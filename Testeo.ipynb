{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iternet testing working",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanigp/IterNet/blob/master/Testeo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KhNjfXfv6qc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635c8842-062d-4f53-c36c-f5a4ca191c5e"
      },
      "source": [
        "! git clone https://github.com/juanigp/IterNet\n",
        "%cd /content/IterNet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IterNet'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 378 (delta 10), reused 7 (delta 2), pack-reused 354\u001b[K\n",
            "Receiving objects: 100% (378/378), 480.80 MiB | 26.18 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "/content/IterNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs0WjHHNv9SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad8e585-36f0-4f7e-e384-1485262ee2e5"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import predict\n",
        "%cp -r \"raw data/.\" \"data/DRIVE/test/images\"\n",
        "predict.predict(stride_size=10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:From /content/IterNet/predict.py:9: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/IterNet/predict.py:9: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/IterNet/predict.py:10: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model : Final_Emer_Iteration_3_cropsize_128_epochs_200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:26<00:00, 26.34s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U02slYljM31v"
      },
      "source": [
        "%mkdir results/iternet\n",
        "%mkdir results/unet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjamYJqAxyEp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8abd0814-d2c8-404f-dd16-9e17e23a213c"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import re\n",
        "\n",
        "def get_pickles_and_store(in_dir, out_dir):\n",
        "  files = os.listdir(in_dir)\n",
        "  files = [file for file in files if '.pickle' in file]\n",
        "  for f in files:\n",
        "    pkl = pickle.load(open( os.path.join(in_dir,f), \"rb\" ) )\n",
        "    im = Image.fromarray(pkl*255)\n",
        "    im = im.convert(\"L\")\n",
        "    basename = os.path.basename(f)\n",
        "    #result = re.search('out4/(.*).pickle', f)\n",
        "    #name = str( int( result.group(1) ) )\n",
        "    name = basename.split('.')[0]\n",
        "    im.save(out_dir + '/' + name + '.png')\n",
        "    #pickle.dump( pkl, open( out_dir + '/' + name + '.pickle', \"wb\" ) )\n",
        "\n",
        "\n",
        "out_dir_iternet = 'results/iternet'\n",
        "out_dir_unet = 'results/unet'\n",
        "get_pickles_and_store(r\"output/DRIVE/crop_size_128/out4/\", out_dir_iternet)\n",
        "get_pickles_and_store(r\"output/DRIVE/crop_size_128/out1/\", out_dir_unet)\n",
        "!zip -r file.zip results\n",
        "\n",
        "\"\"\"\n",
        "files = glob(r\"output/DRIVE/crop_size_128/out4/*.pickle\")\n",
        "for f in files:\n",
        "  #se guarda cada pickle en el directorio results, y tambien se exporta como imagen\n",
        "  pkl = pickle.load(open( f, \"rb\" ) )\n",
        "  im = Image.fromarray(pkl*255)\n",
        "  im = im.convert(\"L\")\n",
        "  result = re.search('out4/(.*).pickle', f)\n",
        "  name = str( int( result.group(1) ) )\n",
        "  im.save(r'results/' + name + '.png')\n",
        "  pickle.dump( pkl, open( r'results/' + name + '.pickle', \"wb\" ) )\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: results/ (stored 0%)\n",
            "  adding: results/.gitignore (deflated 44%)\n",
            "  adding: results/unet/ (stored 0%)\n",
            "  adding: results/unet/01.png (deflated 0%)\n",
            "  adding: results/iternet/ (stored 0%)\n",
            "  adding: results/iternet/01.png (deflated 0%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfiles = glob(r\"output/DRIVE/crop_size_128/out4/*.pickle\")\\nfor f in files:\\n  #se guarda cada pickle en el directorio results, y tambien se exporta como imagen\\n  pkl = pickle.load(open( f, \"rb\" ) )\\n  im = Image.fromarray(pkl*255)\\n  im = im.convert(\"L\")\\n  result = re.search(\\'out4/(.*).pickle\\', f)\\n  name = str( int( result.group(1) ) )\\n  im.save(r\\'results/\\' + name + \\'.png\\')\\n  pickle.dump( pkl, open( r\\'results/\\' + name + \\'.pickle\\', \"wb\" ) )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1b02AwyRQHy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}